import os

MODEL_ROOT_PATH = ""

MODEL_PATH = {
    "embed_model": {
        "text-embedding-ada-002": "",
    },
    # TODO: add all supported llm models
    "llm_model": {

        "gpt2":"gpt2",
        "gpt2-xl":"gpt2-xl",

        "gpt-j-6b":"EleutherAI/gpt-j-6b",
        "gpt4all-j":"nomic-ai/gpt4all-j",
        "gpt-neox-20b":"EleutherAI/gpt-neox-20b",
    },
}

# 选用的 Embedding 名称
EMBEDDING_MODEL = "text-embedding-ada-002"  # 可以尝试最新的嵌入式sota模型：piccolo-large-zh


# Embedding 模型运行设备。设为"auto"会自动检测，也可手动设定为"cuda","mps","cpu"其中之一。
EMBEDDING_DEVICE = "auto"

# LLM 名称
LLM_MODEL = "gpt-3.5-turbo"

# LLM 运行设备。设为"auto"会自动检测，也可手动设定为"cuda","mps","cpu"其中之一。
LLM_DEVICE = "auto"

# 历史对话轮数
HISTORY_LEN = 3

# LLM通用对话参数
TEMPERATURE = 0.7
# TOP_P = 0.95 # ChatOpenAI暂不支持该参数


ONLINE_LLM_MODEL = {
    "gpt-3.5-turbo": {
        "api_base_url": "https://api.openai.com/v1",
        "api_key": "",
        "openai_proxy": "",
    },

}


# 通常情况下不需要更改以下内容

# nltk 模型存储路径
NLTK_DATA_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "nltk_data")


VLLM_MODEL_DICT = {

    "gpt2":"gpt2",
    "gpt2-xl":"gpt2-xl",
    "gpt-j-6b":"EleutherAI/gpt-j-6b",
    "gpt4all-j":"nomic-ai/gpt4all-j",
    "gpt-neox-20b":"EleutherAI/gpt-neox-20b",


}
